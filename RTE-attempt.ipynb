{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b99445f-9435-4240-b4d1-3429fc982bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "def initializeData():\n",
    "    trainFrame = pd.read_json('/Users/nlehr24/Downloads/RTE/train.jsonl', lines=True)\n",
    "\n",
    "    testFrame = pd.read_json('/Users/nlehr24/Downloads/RTE/test.jsonl', lines=True)\n",
    "\n",
    "    valFrame = pd.read_json('/Users/nlehr24/Downloads/RTE/val.jsonl', lines=True)\n",
    "\n",
    "    return trainFrame, testFrame, valFrame\n",
    "\n",
    "train, test, val = initializeData()\n",
    "# print(train.head())\n",
    "# print(test.head())\n",
    "# print(val.head())\n",
    "train = np.array(train)\n",
    "test = np.array(test)\n",
    "val = np.array(val)\n",
    "\n",
    "Y_train = [a[-2] for a in train]\n",
    "X_train = [a[0:2] for a in train]\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "# validation data is the same format as the training. Testing data does not contain entailment dictation\n",
    "Y_val = [a[-2] for a in val]\n",
    "X_val = [a[0:2] for a in val]\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "Y_val = np.array(Y_val)\n",
    "\n",
    "# difficult to turn words into numbers because of all the layers and variable shapes\n",
    "#2/20 3:04 process to ints, then find max sentence length, then fill in non-characters in other sentences with -1\n",
    "# as opposed to image processing, here there is a variable number of inputs\n",
    "def maxxx(threeDarray):\n",
    "    lengths = []\n",
    "    for i in threeDarray:\n",
    "        for j in i:\n",
    "            lengths.append(len(list(j)))\n",
    "\n",
    "    return max(lengths)\n",
    "\n",
    "# combining ver\n",
    "def maxx(twoDarray):\n",
    "    \n",
    "    lengths = []\n",
    "    for s in twoDarray:\n",
    "        lengths.append(len(str(s)))\n",
    "\n",
    "    return max(lengths)\n",
    "\n",
    "# def translateToInts(stringSetArray):\n",
    "#     translated = np.zeros_like(stringSetArray)\n",
    "    \n",
    "#     maxLength = maxxx(stringSetArray)\n",
    "    \n",
    "#     # for each set of sentences,\n",
    "#     for i in range(stringSetArray.shape[0]):\n",
    "\n",
    "#         # for each sentence in each set,\n",
    "#         for j in range(stringSetArray.shape[1]):\n",
    "\n",
    "#             sentence = np.zeros([])\n",
    "\n",
    "#             for k in range(maxLength):\n",
    "#                 try:\n",
    "#                     newChar = ord(stringSetArray[i][j][k])\n",
    "#                 except Exception as e:\n",
    "#                     newChar = -1\n",
    "#                 sentence = np.append(sentence, newChar)\n",
    "    \n",
    "#             translated[i][j] = sentence\n",
    "\n",
    "#     return translated\n",
    "\n",
    "def combine(stringSetArray):\n",
    "    new = list()\n",
    "    for i in range(0, stringSetArray.shape[0]):\n",
    "        # making doubles because not accounting for the changing in length\n",
    "        stringSetArray[i] = stringSetArray[i][0] + stringSetArray[i][1]\n",
    "        \n",
    "        # 2/21 9:44 trying to delete the double made by the indexing reference the uncombined string set array\n",
    "        stringSetArray[i] = np.delete(stringSetArray[i], 1, axis=0)\n",
    "        \n",
    "        new.append(np.delete(stringSetArray[i], 1, axis=0))\n",
    "\n",
    "    return np.array(new)\n",
    "\n",
    "maxLength = maxx(combine(X_train))  # making global so that the model can fit the validation data. This assumes maxx(X_train) > maxx(X_val)\n",
    "# combining ver\n",
    "def translateToInts(stringArray):\n",
    "    translated = list()\n",
    "    \n",
    "    for i in range(stringArray.shape[0]):\n",
    "        sentence = []\n",
    "        string = stringArray[i]\n",
    "\n",
    "        for j in range(maxLength):\n",
    "            # not excluding any characters. Figuring the model can just learn around the []s and 's\n",
    "            \n",
    "            try:\n",
    "                newChar = ord(str(string)[j])\n",
    "            except Exception as e:\n",
    "                newChar = 0\n",
    "            sentence.append(newChar)\n",
    "        # 91: [\n",
    "        # 39: '\n",
    "        # 46: .\n",
    "        translated.append(sentence)\n",
    "      \n",
    "    return np.array(translated)\n",
    "\n",
    "DTC = tree.DecisionTreeClassifier()\n",
    "\n",
    "print('X initial shape:', X_train.shape, X_val.shape)\n",
    "X_train = combine(X_train)\n",
    "X_val = combine(X_val)\n",
    "print('X shape after combining:', X_train.shape, X_val.shape)\n",
    "X_train = translateToInts(X_train)\n",
    "X_val = translateToInts(X_val)\n",
    "print('X shape after translatingToInts:', X_train.shape, X_val.shape)\n",
    "\n",
    "# binarizing Y; if not not entailment save as True. Boolean to int is by default 0 (False) or 1 (True)\n",
    "Y_train = np.array(['not' not in v for v in Y_train], dtype='int')\n",
    "Y_val = np.array(['not' not in v for v in Y_val], dtype='int')\n",
    "\n",
    "\n",
    "print(X_train)\n",
    "print(Y_train)\n",
    "DTC.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "DTCpredictions = DTC.predict(X_val)\n",
    "# DTRpredictions = DTR.predict(X_val) tried using a DecisionTreeRegressor, but did no better than the DecisionTreeClassifier\n",
    "\n",
    "def translateBackToStr(a):\n",
    "    translated = list()\n",
    "    for sentence in a:\n",
    "        new = ''\n",
    "        for int in sentence:\n",
    "            if int != -1:\n",
    "                new += chr(int)\n",
    "        \n",
    "        translated.append(new)\n",
    "    return np.array(translated)\n",
    "\n",
    "X_val = translateBackToStr(X_val)\n",
    "\n",
    "DTCcorrect = 0\n",
    "for i in range(X_val.shape[0]):\n",
    "    if Y_val[i] == DTCpredictions[i]:\n",
    "        DTCcorrect += 1\n",
    "\n",
    "print(f'DTC accuracy: {round(((DTCcorrect / X_val.shape[0]) * 100), 2)}%')\n",
    "\n",
    "def tryNB(X_train, X_val):\n",
    "    if X_val.shape[-1] != X_train.shape[-1]:\n",
    "        X_val = translateToInts(X_val)\n",
    "        \n",
    "    from sklearn.naive_bayes import MultinomialNB\n",
    "    nb = MultinomialNB()\n",
    "    \n",
    "    nb.fit(X_train, Y_train)\n",
    "    \n",
    "    from sklearn import metrics\n",
    "    \n",
    "    # make class predictions for X_test_dtm\n",
    "    y_pred_class = nb.predict(X_val)\n",
    "    \n",
    "    # calculate accuracy of class predictions\n",
    "    print(\"=======Accuracy Score===========\")\n",
    "    print(metrics.accuracy_score(Y_val, y_pred_class))\n",
    "\n",
    "tryNB(X_train, X_val)\n",
    "\n",
    "print('Time taken:', round(time.time() - start, 2))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
